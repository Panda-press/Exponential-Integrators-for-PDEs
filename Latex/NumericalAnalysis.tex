\section{Numerical Analysis}

In this section, we will look into the numerical analysis of the exponential integrators above, combined with the Krylov methods.
We will begin by presenting some already established results for these methods.
Next, we will attempt to extend these results in order to quantify the error produced when using the Krylov methods for approximating the action of the exponential of a matrix to a vector.
We will use $x \lesssim y$ to denote $x \leq C y$ for some $C>0$ independent of $x$ and $y$.
We also use $||\cdot||_1$ and $||\cdot||_0$ to denote the $H^1$ and $H^0$ norms respectively.
\subsection{Formulation of the Problem}
Here we state the problem as formulated by Huang Et al.\cite{Huang2022}.
We begin by considering a parabolic PDE with initial condition of $u_0 \in H^2(\Omega) \cap H^1_0(\Omega)$ of the form:
\begin{align*}
    u_t &= D \Delta u + f(t,u) &x\in \Omega, 0 \leq t \leq T\\
    u(0,x) &= u_0(x) &x\in \Omega\\
    u(t,x) &= 0 &x\in \partial \Omega, 0 \leq t \leq T
\end{align*}
where $T$ is the final time, $\Omega$ is a rectangular domain in $\mathbb{R}^d$, $D\geq 0$, $u(t,x)$ is the unknown function and $f(t,u)$ is a non-linear term.

The variational form of this problem is to find $u\in L^2(0,T;H^1_0(\Omega))$ and $u_t \in L^2(0,T: L^2(\Omega))$ such that
\begin{align*}
    (u_t, v) + a(u, v) &= (f(t,u),v) \quad \forall v \in H^1_0(\Omega), 0\leq t \leq T\\
    u(0) &= u_0
\end{align*}
where $(\cdot,\cdot)$ is the $L^2$ inner product on $\Omega$.
The bilinear form $a(\cdot,\cdot)$ is given by
\begin{align*}
    a(w,v) &= \int_{\Omega} D \nabla w \cdot \nabla v dx, \quad \forall w, v \in H^1_0(\Omega)
\end{align*}
and is clearly symmetric.

We will now begin to formulate the finite element space $V_h$ with which we will approximate $H^1_0$.
As $\Omega \in \mathbb{R}^d$ is a rectangular domain, we can assume that $\bar \Omega := \prod^d_{i=1}[a_i,b_i]$.
For every $i = 1,...,d$, we can define a uniform partition of $[a_i,b_i]$ with the subinterval size $h_i = \frac{b_i - a_i}{N_i}$,
to get the nodes $x^j_i = a_i + jh_i, j = 0,...,N_i$ as $a_i = x_i^0 < x_i^1 < ... < x_i^{N_i} = b_i$.
With this regular partition, we obtain a one-dimensional continuous piecewise linear finite element space for $[a_i,b_i]$.
As
\begin{align*}
    V^i_{h_i}(a_i,b_i) :&= \{v\in C[a_i,b_i]: v|_{[x^{j-1}_i, x^j_i]}\in\mathbb{P}_1([x_i^{j-1},x_i^j]),1\leq j \leq N_i\} \cap H^1_0(a_i,b_i)\\
    &=\text{span}\{\theta^1_i(x_i), ... , \theta^{N_i-1}_i(x_i)\} 
\end{align*}
where $\theta^j_i(x_i)$ is the $j$-th nodal basis function of $V_h^i(a_i,b_i)$. 
Now we can write a finite element space for $\Omega$ as follows:
\begin{align*}
    V_h :&= V_{h_1}^1(a_1,b_1) \otimes ... \otimes V^d_{h_d}(a_d,b_d)\\
    &= \text{span}\{\theta_1^{i_1}\cdot \cdot \cdot \theta_d^{i_d}(x_d): 1 \leq i_1 \leq N_1-1,...,1\leq i_d \leq N_d-1\}
\end{align*}
We now have that $V_h\subset H^1_0(\Omega)$.
Let $h=\text{max}_{1\leq i\leq d}h_i$ be the mesh size of the corresponding uniformly rectangular partition $\mathcal{T}_h$ that generates $V_h$.
All error analysis will assume $h\approx h_i$ for all $i$.

The finite element approximation for the above problem is then to find $u_h \in L^2(0,t:V_h)$ so that:
\begin{align*}
    (u_{h,t},v_h) + a(u_h,v_h) &=(f(t,u_h),v_h) \forall v_h \in V_h, 0\leq t \leq T\\
    u_h(0) &= P_hu_0
\end{align*}
where the $L^2$ orthogonal projection operator is given by $P_h:L^2(\Omega) \rightarrow V_h$.
This projection is stable with respect to the $L_2$, that is to say that $||P_hu||_0 \lesssim ||u||_0$ and $||P_hu||_1 \lesssim ||u||_1$.

The inverse inequality for finite elements (lemma 4.5.3 \cite{Brenner2008}) states that when $V_h \in H^1 \cap H^0$ and $0 < h \leq 1$,
the following holds:
\begin{align*}
    |v|_1 &\lesssim h^{-1} ||v||_0
\end{align*}

From this, we know:
\begin{align}
    a(w_h, v_h) \lesssim |w_h|_1|v_h|_1 \lesssim h^{-2} ||w_h||_0||v_h||_0, \quad \forall w_h, v_h \in V_h \label{bilinear}
\end{align}
where the constants are independent of $h$.
This shows that $a(\cdot,\cdot)$ is a bounded linear form over $V_h$ with respect to the $L_2$ norm.

From here we can apply Riesz representation theorem to deduce that there exists a bounded linear operator $L_h:V_h\rightarrow V_h$ such that
\begin{align*}
    a(w_h, v_h) &= (L_h w_h, v_h), \quad \forall w_h, v_h \in V_h
\end{align*}

Using the projection operator $P_h$, the problem can be rewritten to the equivalent system:
\begin{align*}
    u_{h,t} + L_hu_h &= P_hf(t,u_h)\\
    u_h(0) &= P_hu_0
\end{align*}

\subsection{Established Results}
We now state the results given by Huang, et al\cite{Huang2022}.
Beginning with some assumptions:

\begin{assumption}\label{assump:mildgrowth}
    The function $f(t,\zeta)$ grows mildly with respect to $\zeta$.
    That is there exists a number $p>0$ for $d=1,2$ or $p\in(0,2]$ for $d=3$ such that:
    \begin{align*}
        |\frac{\partial f}{\partial \zeta}| \lesssim 1 + |\zeta|^p. \quad \forall t,\zeta \in \mathbb{R}
    \end{align*}
\end{assumption}
\begin{assumption}\label{assump:smooth}
    The function $f(t, \zeta)$ is sufficiently smooth with respect to $t$.
    That is to say that for any given constant $K>0$ the following holds:
    \begin{align*}
        \sum_{|\alpha|\leq2}|D^{\alpha}f(t,\zeta)|\lesssim 1, \quad \forall t\in [0,T], \zeta \in[-K,K]
    \end{align*}
\end{assumption}
\begin{assumption}\label{assump:regularity}
    The exact solution u(t) satisfies the following regularity conditions:
    \begin{align*}
        \text{sup}_{0\leq t \leq T}||u(t)||_{2,\Omega} \lesssim 1,\\
        \text{sup}_{0\leq t \leq T}||u_t(t)||_{L^\infty(\Omega)} \lesssim 1
    \end{align*}
    Where the hidden constant may depend on $T$.
\end{assumption}
\begin{assumption}\label{assump:regularity2}
    The exact solution u(t) satisfies the following regularity conditions:
    \begin{align*}
        \text{sup}_{0\leq t \leq T}||u_{tt}(t)||_{L^\infty(\Omega)} \lesssim 1
    \end{align*}
    where the hidden constant may depend on $T$.
\end{assumption}

We can now state the theorem that gives the error for the first order exponential integrator scheme.
\begin{theorem}\label{theorem:standard1}
    Suppose the function $f$ satisfies Assumptions \ref{assump:mildgrowth} \ref{assump:smooth} \ref{assump:regularity}.
    There exists a constant $h_0 > 0$ such that for $h<h_0$, we have the numerical solution given by:
    \begin{align*}
        u_h^{n+1} &= e^{-\tau L_h}u_h^n + \tau \varphi_1(-\tau L_h)P_hf(t_n,u_h^n)
    \end{align*}
    satisfies the following:
    \begin{align*}
        ||u(t_n) - u_h^n||_1 &\lesssim \tau + h, \forall n =1,...,N_T
    \end{align*}
    with a hidden constant that is independent of $\tau$ and $h$.
\end{theorem}

We also present the results for the second order exponential integrator scheme.
\begin{theorem}\label{theorem:standard2}
    Suppose the function $f$ satisfies Assumptions \ref{assump:mildgrowth} \ref{assump:smooth} \ref{assump:regularity} and \ref{assump:regularity2}.
    There exists a constant $h_0 > 0$ such that for $h<h_0$, we have the numerical solution given by:
    \begin{align*}
        u_h^{n+1} &= e^{-\tau L_h}u_h^n + \tau (\varphi_1(-\tau L_h) - \frac{1}{c}\varphi_2(-\tau L_h))P_hf(t_n,u_h^n)\\
        &+\frac{1}{c}\varphi_2(-\tau L_h)P_hf(t_n + c\tau,e^{-c\tau L_h}u_h^n + c\tau\varphi_1(-c\tau L_h)P_hf(t_n,u_h^n))
    \end{align*}
    satisfies the following:
    \begin{align*}
        ||u(t_n) - u_h^n||_1 &\lesssim \tau^2 + h, \forall n =1,...,N_T
    \end{align*}
    with a hidden constant that is independent of $\tau$ and $h$.
\end{theorem}

\subsection{Extension to Krylov Methods}

In this section, we will prove the main theorem that ties the error of the first order method to the Krylov methods.
We begin by stating the lemmas that we will need to prove this result.
We omit the proof of lemmas already proven by Huang\cite{Huang2022}.

\begin{lemma} \label{lemma:Lipschitz}
    Suppose that the function $f$ satisfies assumption \ref{assump:mildgrowth}, and the exact solution satisfies \ref{assump:regularity}.
    Then we have that $f$ is locally-Lipschitz continuous in a strip along the exact, i.e. for some $\epsilon > 0$ we have:
    \begin{align*}
        ||f(t,v) - f(t,w)||_0 &\lesssim ||v-w||_1
    \end{align*}
    for any $t\in [0,T]$ and $v,w \in V_h$ satisfying
    \begin{align*}
        \text{max}\{||v-u(t)||_1,||w-u(t)||_1\}\leq \epsilon
    \end{align*}
\end{lemma}

\begin{lemma} \label{lemma:Hnegatvesemidefinite}
    Consider a Krylov approximation given by $V_m^TAV_m = H$ with respect to a vector $v$ of depth $m$.
    If $A$ is negative semi-definite then so is $H$.
\end{lemma}
\begin{proof}
    \begin{align*}
        x^T Hx &= x^T V_m^TAV_mx\\
        &= y^tAy \text{ where $y = V_mx$}\\
        &\leq 0
    \end{align*}
\end{proof}

\begin{definition}
    We let $e_m^A$ denote the Krylov approximation of $e^A$ with respect to some vector $v$ with an $m$ dimensional Krylov subspace.
\end{definition}

For a given $u_h \in V_h$ we have $u_h = \sum^n_{i=1}u_i\theta_i$ where $u_i \in \mathbb{R}$ and $(\theta_i)_{i=1}^n$ are the basis functions of $V_h$.
For much of the remainder of this section, we will associate the matrix $A\in \mathbb{R}^{n\times n}, n=dim(V_h)$ with an operator on $V_h$.
This operator is given as follows: $Au_h = \sum^n_{i=1}\sum^n_{j=1}A_{i,j}u_j\theta_i$.

Likewise for the converse, for a linear opeartor $L_h$ we have a matrix in $\mathbb{R}^{n\times n}$ with coefficients:
$(L_h)_{i,j} = P_{\theta_i}(L_h\theta_j)$

\begin{lemma} \label{lemma:leqm}
    We have that $||e_m^A||_{op} \leq 1$ when $A$ is negative semi-definite.
    The norm $||\cdot||_{op}$ is the operator norm on $H^1$.
    We are considering $e_m^A$ an operator on $H_1$
\end{lemma}
\begin{proof}
    If $A$ is negative semi-definite then so is $H$ by lemma \ref{lemma:Hnegatvesemidefinite} and hence so is $VHV^T$.
    From here we can see that $||e_m^A||_{op} \leq 1$
    Where we consider the matrix $VHV^T$ an operator on the space $V_h$
    % \begin{align*}
    %     ||e_m^A||_{op} &= ||e^{VHV^T}||_{op}\\
    %     &= ||V_me^HV_m^T||_{op}\\
    %     &\leq ||V_m||_{fro}||e^H||_{op}||V_m^T||_{fro}\\
    %     \intertext{We use the fact that $A$ and hence $H$ is negative semi-definite to imply that all of the eigen values $\lambda$ of $H$ are such that $\lambda \leq 0$
    %     and hence we have that $||e^H||_{op} \leq e^0 = 1$. From here we see that}
    %     &\leq ||V_m||_{fro}||V_m^T||_{fro}\\
    %     \intertext{we now use the fact that the $m$ columns of $V_m$ are orthonormal to get}
    %     &= \sqrt{m} \sqrt{m}\\
    %     &= m
    % \end{align*}
\end{proof}

\begin{lemma} \label{lemma:LHnegativeSD}
    $-\tau L_h$ is negative semidefinite. 
    This was briefly shown as part of a lemma previously by Huang \cite{Huang2022}. However, we formally show it here.
\end{lemma}    
\begin{proof}
    As $a(\cdot,\cdot)$ a symmetric bilinear operator, it can be seen that $L_h$ is a linear and symmetric operator that acts on $V_h$.
    We also have by the Poincare inequality that for some $\alpha > 0$:
    \begin{align*}
        \alpha ||v_h||^2_0 \leq a(v_h, v_h), \quad \forall v_h \in V_h
    \end{align*}
    Using this along with (\ref{bilinear}) gives
    \begin{align*}
        0 &\leq \alpha \leq \lambda \quad \forall \lambda \in \lambda(L_h)
    \end{align*} %You should show it with Rayleigh representation theorem
    by Rayleigh representation theorem, where we have that $\lambda(L_h)$ denotes the set of eigen values of $L_h$.
    From here we see that the eigen values of $-\tau L_h$ are negative and hence $-\tau L_h$ is negative semidefinite.
\end{proof}

\begin{definition}
    We write $u_{h,m}^n$ to denote the $n$th step of the exponential integrator method that uses a Krylov subspace of dimension $m$.
    We have that:
    \begin{align*}
        u_{h,m}^n &= e_m^{-\tau L_h} u_{h,m}^{n-1} + \tau \int^1_0e_m^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h,m}^{n-1})
    \end{align*}
    We can associate $L_h$ with a matrix that operates on the basis of $V_h$
\end{definition}

\begin{lemma}
    We claim that $u_{h,m}^n$ satisfies the following condition:
    \begin{align*}
        ||u_{h,m}^n||_1 \lesssim (1-\tau)^\frac{1}{\tau} + (1 + (1 - \tau)\tau)
    \end{align*}
    and hence
    \begin{align*}
        ||P_hf(t,u_{h,m}^n)||_1 \lesssim (1-\tau)^\frac{1}{\tau} + (1 + (1 - \tau)\tau ) + C
    \end{align*}
\end{lemma}
\begin{proof}
    \begin{align*}
        ||u_{h,m}^n||_1 &= ||e_m^{-\tau L_h}u_{h,m}^{n-1} + \tau \int^1_0e_m^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h,m}^{n-1})||_1\\
        &\leq ||e_m^{-\tau L_h}u_{h,m}^{n-1}||_1 + ||\tau \int^1_0e_m^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h,m}^{n-1})||_1\\
        %&= ||V_me_m^{H}V_m^Tu_{h,m}^{n-1}|| + ||\tau \int^1_0V_me_m^{H(1-\theta)}V_m^Td\theta P_hf(t, u_{h,m}^{n-1})||_1\\
        \intertext{We now apply lemmas \ref{lemma:LHnegativeSD} and \ref{lemma:leqm} to show that}
        &\leq ||u_{h,m}^{n-1}||_1 + \tau ||P_hf(t_{n-1},u_{h,m}^{n-1})||_1\\
        \intertext{we have that $||P_hf(t,u)||_1 \lesssim ||u||_1+||P_hf(t,0)||_1$ by Lipschitz continuity of $f$ giving}
        &\lesssim ||u_{h,m}^{n-1}||_1 + \tau m (||u_{h,m}^{n-1}||_1 + ||P_hf(t,0)||_1)\\
        &\lesssim (1-\tau)^n||u_{h,m}^0||_1 + \tau ||P_hf(t,0)||_1(n + (n -1)\tau)\\
        &\lesssim (1-\tau)^n + \tau (n + (n -1)\tau)\\
        &\lesssim (1-\tau)^\frac{1}{\tau} + \tau (\frac{1}{\tau} + (\frac{1}{\tau} -1)\tau)\\
        &\lesssim (1-\tau)^\frac{1}{\tau} + (1 + (1 - \tau)\tau)
    \end{align*}
    with the bound on $P_hf(t,u_{h,m}^n)$ being the result of Lipschitz continuity by taking $P_hf(t,0)\lesssim C$.
    This assumes that $P_hf(t,0)$ is bounded for all $t$ which I think should follow from assumption \ref{assump:smooth}.
\end{proof}
\begin{definition}
    The error from the Krylov subspace approximation is given by $k(m,\tau, L_h)$.
    Associating $L_h$ with a matrix that operates on the basis of $V_h$
    We define $k(m,\tau, L_h)$:
    \begin{align*}
        k(m,\tau, L_h) &= max_{||v||_1=1}||e^{\tau A}v - V_m e^{H_m}V^T_mv||_1\\
    \end{align*}
    Where $V_m$ and $H_m$ are generated by our Krylov methods.
\end{definition}
\begin{lemma}\label{lemma:krylovbound}
    For $0\leq \tau \leq 1$
    The error between $u_{h,m}^n$ and $u_{h}^n$ is given by:
    \begin{align*}
        ||u_{h,m}^n - u_{h}^n||_1 \lesssim k(m,\tau, L_h)(\frac{1}{\tau})
    \end{align*}
    where $k(m,\tau,L_h)$ denotes the error from the Krylov approximation that is dependant on $m, \tau, L_h$.
\end{lemma}
\begin{proof}
    \begin{align*}
        ||u_{h,m}^n - u_{h}^n||_1 &= ||e_m^{-\tau L_h}u_{h,m}^{n-1} - e^{-\tau L_h}u_{h}^{n-1}\\
        & + \tau(\int^1_0e_m^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h,m}^{n-1}) - \int^1_0e^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h}^{n-1}))||_1\\
        &= ||(e_m^{-\tau L_h}-e^{-\tau L_h})u_{h,m}^{n-1} \\
        & + e^{-\tau L_h}(u_{h,m}^{n-1}-u_{h}^{n-1})\\
        & + \tau(\int^1_0 (e_m^{-\tau L_h(1-\theta)}-e^{-\tau L_h(1-\theta)}) d\theta P_hf(t, u_{h,m}^{n-1})\\
        & + \int^1_0e^{-\tau L_h(1-\theta)}d\theta P_hf(t, u_{h,m}^{n-1}- P_hf(t, u_{h}^{n-1})))||_1\\
        \intertext{using Lipschitz continuity of $f$ from lemma \ref{lemma:Lipschitz} and triangle inequality}
        & \lesssim ||(e_m^{-\tau L_h}-e^{-\tau L_h})u_{h,m}^{n-1}||_1 \\
        & + ||e^{-\tau L_h}(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & + \tau||\int^1_0 (e_m^{-\tau L_h(1-\theta)}-e^{-\tau L_h(1-\theta)}) d\theta P_hf(t, u_{h,m}^{n-1})||_1 \\
        & + \tau||\int^1_0e^{-\tau L_h(1-\theta)}d\theta (u_{h,m}^{n-1}- u_{h}^{n-1})||_1 \\
        & \lesssim ||(e_m^{-\tau L_h}-e^{-\tau L_h})\frac{u_{h,m}^{n-1}}{||u_{h,m}^{n-1}||_1}||_1||u_{h,m}^{n-1}||_1 \\
        & + ||e^{-\tau L_h}||_{op}||(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & + \tau||\int^1_0 (e_m^{-\tau L_h(1-\theta)}-e^{-\tau L_h(1-\theta)}) d\theta \frac{P_hf(t, u_{h,m}^{n-1})}{|| P_hf(t, u_{h,m}^{n-1})||_1}|||| P_hf(t, u_{h,m}^{n-1})||_1 \\
        & + \tau||\int^1_0e^{-\tau L_h(1-\theta)}d\theta||_{op}|| (u_{h,m}^{n-1}- u_{h}^{n-1})||_1 \\
        & \lesssim k(m,\tau, L_h)||u_{h,m}^{n-1}||_1 \\
        & + ||(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & + \tau k(m,\tau, L_h)|| P_hf(t, u_{h,m}^{n-1})||_1 \\
        & + \tau||(u_{h,m}^{n-1}- u_{h}^{n-1})||_1 \\
        & \lesssim k(m,\tau, L_h)||u_{h,m}^{n-1}||_1 \\
        & + (1+\tau)||(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & + \tau k(m,\tau, L_h)(||u_{h,m}^{n-1}||_1 + C)\\
        & \lesssim (1+\tau)k(m,\tau, L_h)(||u_{h,m}^{n-1}||_1 + C) \\
        & + (1+\tau)||(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & \lesssim (1+\tau)k(m,\tau, L_h)((1-\tau)^\frac{1}{\tau} + (1 + (1 - \tau)\tau) + C) \\
        & + (1+\tau)||(u_{h,m}^{n-1}-u_{h}^{n-1})||_1 \\
        & \lesssim \sum^n_{i=1}[(1+\tau)^i]k(m,\tau, L_h)((1-\tau)^\frac{1}{\tau} + (1 + (1 - \tau)\tau) + C)\\
        & \lesssim k(m,\tau, L_h)((1-\tau 1)^\frac{1}{\tau} + (1 + (1 - \tau)\tau ) + C)\frac{1-(1+\tau)^{\frac{1}{\tau} + 1}}{\tau}
        \intertext{we observe that $(1-\tau)^\frac{1}{\tau} \leq 1$, that $m (1 + (1 - \tau)\tau m) \lesssim m$ for $0\leq \tau \leq 1$ and $\frac{1-(1+\tau)^{\frac{1}{\tau} + 1}}{\tau} \lesssim 1 + \frac{1}{\tau}$}
        & \lesssim k(m,\tau, L_h)(\frac{1}{\tau}) \text{also using that $\frac{1}{\tau} \geq 1$ for $0 \leq \tau \leq 1$}
    \end{align*}
\end{proof}

We can now prove the main theorem
\begin{theorem}
    Suppose the function $f$ satisfies Assumptions \ref{assump:mildgrowth} \ref{assump:smooth} \ref{assump:regularity} and that $0\leq \tau \leq 1$
    There exists a constant $h_0 > 0$ such that for $h<h_0$ we have
    \begin{align*}
        ||u(t_n) - u_{h,m}^n||_1 \lesssim \tau + h + k(m,\tau, L_h)(\frac{1}{\tau}), \forall n = 1,..,N_T
    \end{align*}
\end{theorem}
\begin{proof}
    \begin{align*}
        ||u(t_n) - u_{h,m}^n||_1 &= ||u(t_n) - u_h^n + u_h^n - u_{h,m}^n||_1\\
        &\leq ||u(t_n) - u_h^n||_1 + ||u_h^n - u_{h,m}^n||_1
        \intertext{by the triangle inequality. We can now use theorem \ref{theorem:standard1} and lemma \ref{lemma:krylovbound} to see that}
        &\leq \tau + h + k(m,\tau, L_h)(\frac{1}{\tau}), \forall n =1,...,N_T
    \end{align*}
\end{proof}

\begin{corollary}
    Let $v\in V_h$ and $v'\in \mathbb{R}^{n\times n}$ with $n = dim(V_h)$ represents its coefficients.
    If we assume that $\exists c_h,C_h \in \mathbb{R}$ such that $c_h||v'|| \leq ||v||_1 \leq C_h||v'||$ holds for all $v$, where $||\cdot||$ is the Euclidian norm and $c_h,C_h$ may depend on $V_h$.
    Likewise, assuming that $\exists c_{op}$ such that $||L_h||_{op} \leq c_{op} ||L_h||_{opm}||$, where $||\cdot||_{op}$ and $||\cdot||_{opm}$ represents the opeartor nomrs for operators on $H^1$ and $\mathbb{R}^n$ respectively.
    $c_{op}$ again depends on $V_h$.
    Then using the above theorem alongside what we already know about the convergence rates of Krylov subspaces we can observe the following:
    \begin{align*}
        ||u(t_n) - u_{h,m}^n||_1 \lesssim \tau + h + 2 \frac{(\tau \rho)^m e^{\tau \rho}}{m!}h(\frac{1}{\tau}), \forall n = 1,..,N_T
    \end{align*}
    where $c_{op}||L_h||_{opm} = \rho$.
\end{corollary}
\begin{proof}
    \begin{align*}
        ||u(t_n) - u_{h,m}^n||_1 &\lesssim \tau + h + k(m,\tau, L_h)(\frac{1}{\tau})\\
        &\lesssim \tau + h + (\frac{1}{\tau})max_{||v||_1=1 v\in V_h}||e^{\tau L_h}v - V_m e_m^{L_h}V^T_mv||_1 \\
        \intertext{considering $v'$ to be the coefficients of $v\in V_h$ and the matrices of the operators $e^{-\tau L_h}$ and $V_m e^{-\tau L_h} V^T_m$ we get the following}
        &\lesssim \tau + h + (\frac{1}{\tau})C_hmax_{||v||_1=1 v\in V_h}||e^{\tau L_h}v - V_m e_m^{L_h}V^T_mv||_{fro}\\
        &\lesssim \tau + h + (\frac{1}{\tau})max_{||v||_1=1 v\in V_h}||v||_{fro}||e^{\tau L_h}\frac{v}{||v||_{fro}} - V_m e_m^{L_h}V^T_m\frac{v}{||v||_{fro}}||_{fro}\\
        &\lesssim \tau + h + (\frac{1}{\tau})c_h C_h\frac{(\tau \rho)^m e^{\tau \rho}}{m!}
    \end{align*}
\end{proof}

Further work is neccessary inorder to determin $c_h,C_h,c_{op}$
